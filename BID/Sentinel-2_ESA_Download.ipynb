{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import snappy_utils\n",
    "import os, sys\n",
    "import json\n",
    "sys.path.append(\"../\")\n",
    "import settings\n",
    "from sentinelsat.sentinel import SentinelAPI, read_geojson, geojson_to_wkt\n",
    "from datetime import date, datetime\n",
    "import zipfile\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "footprint = settings.footprint\n",
    "sentinel_api_user = settings.sentinel_api_user\n",
    "sentinel_api_key = settings.sentinel_api_key\n",
    "data_path = settings.data_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentinelsat API wrapper class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sentinelsat_products:\n",
    "    def __init__(self, date_start, date_finish, footprint=footprint, platformname=\"Sentinel-2\"):\n",
    "        self.date_start = date_start\n",
    "        self.date_finish = date_finish\n",
    "        self.platform = platformname\n",
    "        self.api = SentinelAPI(sentinel_api_user, sentinel_api_key, 'https://scihub.copernicus.eu/dhus')\n",
    "        #self.api.logger.setLevel(logging.DEBUG)\n",
    "        self.wkt_footprint = footprint\n",
    "        self.products = self.query_products(self.date_start, self.date_finish)\n",
    "        self.downloaded_prods, self.retrieval_scheduled, self.failed_prods = {}, {}, {}\n",
    "\n",
    "    def query_products(self, date_start, date_finish, platformname=\"Sentinel-2\"):\n",
    "        # search by polygon, time, and Hub query keywords\n",
    "        products = self.api.query(self.wkt_footprint, area_relation='Contains',\n",
    "                            date = (self.date_start, self.date_finish),\n",
    "                            platformname = platformname)\n",
    "        return products\n",
    "    \n",
    "    def filter_products(self, instrument, level, p_type, timeliness):\n",
    "        removed_products = []\n",
    "        for product_key in self.products:\n",
    "            odata = self.api.get_product_odata(product_key, full=True)\n",
    "            #print(odata)\n",
    "            if self.platform == \"Sentinel-3\":\n",
    "                product_instrument = odata[\"Instrument\"]\n",
    "                product_level = odata[\"Product level\"]\n",
    "                product_type = odata[\"Product type\"]\n",
    "                mission_type = odata[\"Mission type\"]\n",
    "                product_timeliness = odata[\"Timeliness Category\"]\n",
    "                #filter only from Level 1 OLCI instrument with NTC full resolution\n",
    "                conditions = (\n",
    "                (product_instrument == instrument) and (p_type in product_type) \n",
    "                and product_timeliness == timeliness and product_level == level\n",
    "                            )\n",
    "            if self.platform == \"Sentinel-2\":\n",
    "                product_instrument = odata[\"Instrument\"]\n",
    "                product_level = odata[\"Processing level\"]            \n",
    "                conditions = (product_instrument == instrument) and (product_level == level)\n",
    "            #keep list of pids of products that meet downloading conditions\n",
    "            if conditions:\n",
    "                #print(instrument, product_level, product_type)\n",
    "                pass                \n",
    "            else:\n",
    "                removed_products.append(product_key)\n",
    "        #remove products that didn't meet the download conditions\n",
    "        for key in removed_products:\n",
    "            del self.products[key]\n",
    "\n",
    "    def download_products(self, delete_zip=True, lta_request_delay=600):\n",
    "        total_products = len(self.products.keys())\n",
    "        current_product = 1\n",
    "        for key in self.products:\n",
    "            print(\"-------------------------\")\n",
    "            print(current_product, \"/\", total_products)\n",
    "            current_product += 1\n",
    "            product_odata = self.api.get_product_odata(key, full=True)\n",
    "            file_name = self.products[key][\"filename\"]\n",
    "            file_date = self.products[key][\"summary\"][:16].split(\"Date: \")[1]\n",
    "            print(file_date)\n",
    "            download_path = os.path.join(data_path, file_date)\n",
    "            if not os.path.exists(download_path):\n",
    "                os.makedirs(download_path)\n",
    "            # if it was downloaded before or is offline it won't download\n",
    "            if file_name in os.listdir(download_path):\n",
    "                print(\"Data from\", file_date, \"already downloaded\")\n",
    "                self.downloaded_prods[key] = self.products[key]\n",
    "                continue\n",
    "            if self.api.is_online(key) == False:\n",
    "                print(\"Data from\", file_date, \"offline\")\n",
    "                if key in list(self.retrieval_scheduled.keys()):\n",
    "                    print(\"LTA retrieval already triggered\")\n",
    "                    continue\n",
    "                try:\n",
    "                    lta_status_response = self.api._trigger_offline_retrieval(product_odata[\"url\"])\n",
    "                except Exception as e:\n",
    "                    print(\"RAISED EXCEPTION:\", str(e))\n",
    "                    print(\"///////////////////////////\")\n",
    "                    self.failed_prods[key] = self.products[key]\n",
    "                    continue\n",
    "                if lta_status_response == 202:\n",
    "                    print(\"Accepted for retrieval\")\n",
    "                    self.retrieval_scheduled[key] = self.products[key]\n",
    "                    continue\n",
    "                elif lta_status_response == 403:\n",
    "                    while(lta_status_response == 403):\n",
    "                        print(\"Requests exceed user quota. Retrying in %s seconds\" % (lta_request_delay))\n",
    "                        time.sleep(lta_request_delay)\n",
    "                        lta_status_response = self.api._trigger_offline_retrieval(product_odata[\"url\"])\n",
    "                    if lta_status_response == 202:\n",
    "                        print(\"Accepted for retrieval\")\n",
    "                        self.retrieval_scheduled[key] = self.products[key]\n",
    "                continue\n",
    "            try:\n",
    "                download_info = self.api.download(key, directory_path=download_path)\n",
    "                zip_path = download_info[\"path\"]\n",
    "                with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "                    zip_ref.extractall(download_path)\n",
    "                self.downloaded_prods[key] = self.products[key]\n",
    "            except Exception as e:\n",
    "                print(\"RAISED EXCEPTION:\", str(e))\n",
    "                print(\"/////////////\")\n",
    "                self.failed_prods[key] = self.products[key]\n",
    "                continue\n",
    "            if delete_zip:\n",
    "                os.remove(zip_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generic data download code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date1 = date(2015, 11, 1)\n",
    "date2 = date(2016, 5, 31)\n",
    "\n",
    "datos = Sentinelsat_products(date1, date2, footprint=footprint)\n",
    "datos.filter_products(instrument=\"MSI\", level=\"Level-2A\", p_type=None, timeliness=None)\n",
    "datos.download_products()\n",
    "\n",
    "datos = Sentinelsat_products(date1, date2, footprint=footprint)\n",
    "datos.filter_products(instrument=\"MSI\", level=\"Level-1C\", p_type=None, timeliness=None)\n",
    "datos.download_products()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download 2015-2016 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Starting datetime:\", str(datetime.now()))\n",
    "\n",
    "date1 = date(2015, 11, 1)\n",
    "date2 = date(2016, 5, 31)\n",
    "\n",
    "datos__2016_2015 = Sentinelsat_products(date1, date2, footprint=footprint)\n",
    "datos__2016_2015.filter_products(instrument=\"MSI\", level=\"Level-1C\", p_type=None, timeliness=None)\n",
    "datos__2016_2015.download_products()\n",
    "print(\"Finish datetime: \", str(datetime.now()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download 2017-2018 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Starting datetime:\", str(datetime.now()))\n",
    "\n",
    "date1 = date(2017, 11, 1)\n",
    "date2 = date(2018, 5, 31)\n",
    "\n",
    "datos__2017_2018 = Sentinelsat_products(date1, date2, footprint=footprint)\n",
    "datos__2017_2018.filter_products(instrument=\"MSI\", level=\"Level-1C\", p_type=None, timeliness=None)\n",
    "datos__2017_2018.download_products()\n",
    "print(\"Finish datetime: \", str(datetime.now()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download 2018-2019 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Starting datetime:\", str(datetime.now()))\n",
    "\n",
    "date1 = date(2018, 11, 1)\n",
    "date2 = date(2019, 5, 31)\n",
    "\n",
    "datos__2018_2019 = Sentinelsat_products(date1, date2, footprint=footprint)\n",
    "datos__2018_2019.filter_products(instrument=\"MSI\", level=\"Level-1C\", p_type=None, timeliness=None)\n",
    "datos__2018_2019.download_products()\n",
    "\n",
    "print(\"Finish datetime: \", str(datetime.now()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download 2019-2020 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Start datetime:\", str(datetime.now()))\n",
    "\n",
    "date1 = date(2019, 11, 1)\n",
    "date2 = date(2020, 5, 31)\n",
    "\n",
    "datos__2019_2020 = Sentinelsat_products(date1, date2, footprint=footprint)\n",
    "datos__2019_2020.filter_products(instrument=\"MSI\", level=\"Level-1C\", p_type=None, timeliness=None)\n",
    "datos__2019_2020.download_products()\n",
    "\n",
    "print(\"Finish datetime: \", str(datetime.now()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download 2020-2021 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date1 = date(2020, 11, 1)\n",
    "date2 = date(2021, 3, 27)\n",
    "\n",
    "datos__2020_2021 = Sentinelsat_products(date1, date2, footprint=footprint)\n",
    "datos__2020_2021.filter_products(instrument=\"MSI\", level=\"Level-1C\", p_type=None, timeliness=None)\n",
    "datos__2020_2021.download_products()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cyano_venv_true",
   "language": "python",
   "name": "cyano_venv_true"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
