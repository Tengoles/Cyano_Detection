{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: IERSStaleWarning: leap-second file is expired. [astropy.utils.iers.iers]\n",
      "WARNING:astropy:IERSStaleWarning: leap-second file is expired.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "import settings\n",
    "from datetime import date, datetime\n",
    "import time\n",
    "from IPython.display import clear_output\n",
    "import traceback\n",
    "\n",
    "from prediction_dataset import PredictionDataset\n",
    "from process_sentinel3 import OLCIdataGenerator\n",
    "from sentinelsat_download import SentinelsatProducts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "footprint = settings.footprint\n",
    "data_path = settings.raw_data_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download all data between two dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date1 = date(2021, 1, 1)\n",
    "date2 = date(2021, 12, 31)\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        datos = SentinelsatProducts(date1, date2, footprint=footprint, \n",
    "                                    platformname=\"Sentinel-3\", instrument=\"SLSTR\", \n",
    "                                    level=\"L2\", p_type=\"SL_2_LST___\")\n",
    "        #datos.filter_products(instrument=\"SLSTR\", level=\"L2\", p_type=\"SL_2_LST___\", timeliness=\"Non Time Critical\")\n",
    "        datos.download_products(data_path)\n",
    "    except Exception as e:\n",
    "        clear_output(wait=True)\n",
    "        print(\"/\"*20)\n",
    "        print(str(e))\n",
    "        print(\"/\"*20)\n",
    "        time.sleep(60*10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download data from valid Sentinel-2 days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = settings.data_path\n",
    "DATE_FORMAT = '%Y-%m-%d'\n",
    "START_DATE = '2016-12-21'\n",
    "END_DATE = '2022-04-20'\n",
    "\n",
    "data_generator = DayDataGenerator(START_DATE, END_DATE, DATE_FORMAT, DATA_PATH, skip_invalid=True)\n",
    "valid_dates = [day.date.date() for day in data_generator]\n",
    "print(\"Total days to download:\", len(valid_dates))\n",
    "while True:\n",
    "    date1 = date(2016, 12, 21)\n",
    "    date2 = date(2022, 4, 20)\n",
    "    try:\n",
    "        datos = SentinelsatProducts(date1, date2, footprint=footprint, \n",
    "                                    platformname=\"Sentinel-3\", instrument=\"SLSTR\", \n",
    "                                    level=\"L2\", p_type=\"SL_2_LST___\")\n",
    "        datos.filter_by_dates(valid_dates)\n",
    "        datos.download_products(data_path)\n",
    "    except Exception as e:\n",
    "        clear_output(wait=True)\n",
    "        print(\"/\"*20)\n",
    "        print(traceback.format_exc())\n",
    "        print(\"/\"*20)\n",
    "        time.sleep(60*10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_folder_size(folder_path):\n",
    "    size = 0\n",
    "    for path, dirs, files in os.walk(folder_path):\n",
    "        for f in files:\n",
    "            fp = os.path.join(path, f)\n",
    "            size += os.path.getsize(fp)/1024/1024\n",
    "    return size\n",
    "\n",
    "def get_sentinel_folder_datetime(folder_path):\n",
    "    folder_name = os.path.basename(folder_path)\n",
    "    return datetime.strptime(folder_name.split(\"____\")[1].split(\"_\")[0][0:15], \"%Y%m%dT%H%M%S\")\n",
    "    \n",
    "\n",
    "dirs_to_delete = {}\n",
    "for day_dir in os.listdir(DATA_PATH):\n",
    "    sen3_dirs = [os.path.join(DATA_PATH, day_dir, sat_data) for sat_data in os.listdir(os.path.join(DATA_PATH, day_dir)) if sat_data.endswith(\"SEN3\")]\n",
    "    sen3_dir_size = [get_folder_size(s3_data) for s3_data in sen3_dirs]    \n",
    "    sen3_dir_dt = [get_sentinel_folder_datetime(s3_data) for s3_data in sen3_dirs]    \n",
    "    \n",
    "    small_dirs = [[sen3_dirs[i], dir_size] for i, dir_size in enumerate(sen3_dir_size) if dir_size < 1000]\n",
    "    big_dirs = [[sen3_dirs[i], dir_size] for i, dir_size in enumerate(sen3_dir_size) if dir_size > 1000]\n",
    "    \n",
    "    if len(small_dirs) > 0:\n",
    "        for big_dir in big_dirs:\n",
    "            dirs_to_delete[big_dir[0]] = big_dir[1]  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download data from relevant Sentinel-3 days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data_path = settings.processed_data_path\n",
    "\n",
    "DATE_FORMAT = '%Y-%m-%d'\n",
    "\n",
    "ndci_data_path = os.path.join(settings.final_data_path, \"kmeans_3\", \"ndci_data.csv\")\n",
    "precipitation_data_path = os.path.join(settings.final_data_path, \"precipitation\", \"precipitation_pdir.csv\")\n",
    "wind_data_path = os.path.join(settings.final_data_path, \"wind_data.csv\")\n",
    "water_temperature_data_path = os.path.join(settings.final_data_path, \"water_temperature.csv\")\n",
    "algae_gt_path = os.path.join(settings.final_data_path, \"algae_gt.csv\")\n",
    "ta_ose_path = os.path.join(settings.final_data_path, \"agua_open_data(1).csv\")\n",
    "s3_brrs_path = os.path.join(settings.final_data_path, \"s3_brrs.json\")\n",
    "\n",
    "raw_cyano_gt_path = os.path.join(settings.final_data_path, \"MUESTREOS_SEMANALES_2016-2017-2018-2019-2020.xls\")\n",
    "\n",
    "# bloom_thresholds = {\n",
    "#                     \"MALLORQUINA\":5000,\n",
    "#                     \"ARROYO SAUCE\": 5000,\n",
    "#                     \"SAUCE NORTE\": 5000,\n",
    "#                     \"SAUCE SUR\": 5000,\n",
    "#                     \"CISNES\": 5000,\n",
    "#                     \"POTRERO\": 5000,\n",
    "#                     \"TA\":5000\n",
    "#                    }\n",
    "bloom_thresholds = {\n",
    "                    \"MALLORQUINA\":5000,\n",
    "                    \"ARROYO SAUCE\": 5000,\n",
    "                    \"SAUCE NORTE\": 5000,\n",
    "                    \"SAUCE SUR\": 5000,\n",
    "                    \"CISNES\": 5000,\n",
    "                    \"POTRERO\": 5000,\n",
    "                    \"TA\":3000\n",
    "                   }\n",
    "\n",
    "sampling_points_coords = {\"SAUCE NORTE\": [-34.795398, -55.047355],\n",
    "                          \"SAUCE SUR\": [-34.843127, -55.064624],\n",
    "                          \"TA\": [-34.829670, -55.049758]}\n",
    "\n",
    "pre_bloom_max_days = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../prediction_dataset.py:106: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  location_df['label'] = location_df['fico'].apply(lambda x: 'Bloom' if x > threshold else 'No Bloom')\n",
      "../prediction_dataset.py:180: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  location_data_df[\"days until bloom\"] = days_until_bloom\n"
     ]
    }
   ],
   "source": [
    "dataset = PredictionDataset(wind_data_path, water_temperature_data_path, precipitation_data_path, \n",
    "                            ndci_data_path, algae_gt_path, s3_brrs_path, bloom_thresholds=bloom_thresholds, \n",
    "                            pre_bloom_max_days=pre_bloom_max_days)\n",
    "\n",
    "gt_dates = set([d.date() for d in dataset.algae_gt.date.tolist()])\n",
    "\n",
    "olci_data_generator = OLCIdataGenerator(processed_data_path, DATE_FORMAT, skip_invalid=True)\n",
    "clear_olci_dates = set([olci_data.date.date() for olci_data in olci_data_generator])\n",
    "\n",
    "relevant_dates = list(gt_dates.intersection(clear_olci_dates))\n",
    "relevant_dates.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "while True:\n",
    "    date1 = relevant_dates[0]\n",
    "    date2 = relevant_dates[-1]\n",
    "    try:\n",
    "        datos = SentinelsatProducts(date1, date2, footprint=footprint, \n",
    "                                    platformname=\"Sentinel-3\", instrument=\"SLSTR\", \n",
    "                                    level=\"L2\", p_type=\"SL_2_LST___\")\n",
    "        datos.filter_by_dates(relevant_dates, filter_time_of_day=True)\n",
    "        datos.download_products(data_path)\n",
    "    except Exception as e:\n",
    "        clear_output(wait=True)\n",
    "        print(\"/\"*20)\n",
    "        print(traceback.format_exc())\n",
    "        print(\"/\"*20)\n",
    "        time.sleep(60*10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cyano_venv",
   "language": "python",
   "name": "cyano_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
